/**
 * This file was auto-generated by Fern from our API Definition.
 */
package com.assemblyai.api.resources.lemur.requests;

import com.assemblyai.api.core.ObjectMappers;
import com.assemblyai.api.types.ILemurBaseParameters;
import com.assemblyai.api.types.LemurBaseParametersContext;
import com.assemblyai.api.types.LemurModels;
import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonSetter;
import com.fasterxml.jackson.annotation.Nulls;
import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
import java.util.ArrayList;
import java.util.List;
import java.util.Objects;
import java.util.Optional;

@JsonInclude(JsonInclude.Include.NON_EMPTY)
@JsonDeserialize(builder = LemurTaskParameters.Builder.class)
public final class LemurTaskParameters implements ILemurBaseParameters {
    private final List<String> transcriptIds;

    private final Optional<LemurBaseParametersContext> context;

    private final Optional<LemurModels> finalModel;

    private final Optional<Integer> maxOutputSize;

    private final Optional<Double> temperature;

    private final String prompt;

    private LemurTaskParameters(
            List<String> transcriptIds,
            Optional<LemurBaseParametersContext> context,
            Optional<LemurModels> finalModel,
            Optional<Integer> maxOutputSize,
            Optional<Double> temperature,
            String prompt) {
        this.transcriptIds = transcriptIds;
        this.context = context;
        this.finalModel = finalModel;
        this.maxOutputSize = maxOutputSize;
        this.temperature = temperature;
        this.prompt = prompt;
    }

    /**
     * @return A list of completed transcripts with text. Up to 100 files max, or 100 hours max. Whichever is lower.
     */
    @JsonProperty("transcript_ids")
    @Override
    public List<String> getTranscriptIds() {
        return transcriptIds;
    }

    /**
     * @return Context to provide the model. This can be a string or a free-form JSON value.
     */
    @JsonProperty("context")
    @Override
    public Optional<LemurBaseParametersContext> getContext() {
        return context;
    }

    @JsonProperty("final_model")
    @Override
    public Optional<LemurModels> getFinalModel() {
        return finalModel;
    }

    /**
     * @return Max output size in tokens. Up to 4000 allowed.
     */
    @JsonProperty("max_output_size")
    @Override
    public Optional<Integer> getMaxOutputSize() {
        return maxOutputSize;
    }

    /**
     * @return The temperature to use for the model.
     * Higher values result in answers that are more creative, lower values are more conservative.
     * Can be any value between 0.0 and 1.0 inclusive.
     */
    @JsonProperty("temperature")
    @Override
    public Optional<Double> getTemperature() {
        return temperature;
    }

    /**
     * @return Your text to prompt the model to produce a desired output, including any context you want to pass into the model.
     */
    @JsonProperty("prompt")
    public String getPrompt() {
        return prompt;
    }

    @Override
    public boolean equals(Object other) {
        if (this == other) return true;
        return other instanceof LemurTaskParameters && equalTo((LemurTaskParameters) other);
    }

    private boolean equalTo(LemurTaskParameters other) {
        return transcriptIds.equals(other.transcriptIds)
                && context.equals(other.context)
                && finalModel.equals(other.finalModel)
                && maxOutputSize.equals(other.maxOutputSize)
                && temperature.equals(other.temperature)
                && prompt.equals(other.prompt);
    }

    @Override
    public int hashCode() {
        return Objects.hash(
                this.transcriptIds, this.context, this.finalModel, this.maxOutputSize, this.temperature, this.prompt);
    }

    @Override
    public String toString() {
        return ObjectMappers.stringify(this);
    }

    public static PromptStage builder() {
        return new Builder();
    }

    public interface PromptStage {
        _FinalStage prompt(String prompt);

        Builder from(LemurTaskParameters other);
    }

    public interface _FinalStage {
        LemurTaskParameters build();

        _FinalStage transcriptIds(List<String> transcriptIds);

        _FinalStage addTranscriptIds(String transcriptIds);

        _FinalStage addAllTranscriptIds(List<String> transcriptIds);

        _FinalStage context(Optional<LemurBaseParametersContext> context);

        _FinalStage context(LemurBaseParametersContext context);

        _FinalStage finalModel(Optional<LemurModels> finalModel);

        _FinalStage finalModel(LemurModels finalModel);

        _FinalStage maxOutputSize(Optional<Integer> maxOutputSize);

        _FinalStage maxOutputSize(Integer maxOutputSize);

        _FinalStage temperature(Optional<Double> temperature);

        _FinalStage temperature(Double temperature);
    }

    @JsonIgnoreProperties(ignoreUnknown = true)
    public static final class Builder implements PromptStage, _FinalStage {
        private String prompt;

        private Optional<Double> temperature = Optional.empty();

        private Optional<Integer> maxOutputSize = Optional.empty();

        private Optional<LemurModels> finalModel = Optional.empty();

        private Optional<LemurBaseParametersContext> context = Optional.empty();

        private List<String> transcriptIds = new ArrayList<>();

        private Builder() {}

        @Override
        public Builder from(LemurTaskParameters other) {
            transcriptIds(other.getTranscriptIds());
            context(other.getContext());
            finalModel(other.getFinalModel());
            maxOutputSize(other.getMaxOutputSize());
            temperature(other.getTemperature());
            prompt(other.getPrompt());
            return this;
        }

        /**
         * <p>Your text to prompt the model to produce a desired output, including any context you want to pass into the model.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @Override
        @JsonSetter("prompt")
        public _FinalStage prompt(String prompt) {
            this.prompt = prompt;
            return this;
        }

        /**
         * <p>The temperature to use for the model.
         * Higher values result in answers that are more creative, lower values are more conservative.
         * Can be any value between 0.0 and 1.0 inclusive.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @Override
        public _FinalStage temperature(Double temperature) {
            this.temperature = Optional.of(temperature);
            return this;
        }

        @Override
        @JsonSetter(value = "temperature", nulls = Nulls.SKIP)
        public _FinalStage temperature(Optional<Double> temperature) {
            this.temperature = temperature;
            return this;
        }

        /**
         * <p>Max output size in tokens. Up to 4000 allowed.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @Override
        public _FinalStage maxOutputSize(Integer maxOutputSize) {
            this.maxOutputSize = Optional.of(maxOutputSize);
            return this;
        }

        @Override
        @JsonSetter(value = "max_output_size", nulls = Nulls.SKIP)
        public _FinalStage maxOutputSize(Optional<Integer> maxOutputSize) {
            this.maxOutputSize = maxOutputSize;
            return this;
        }

        @Override
        public _FinalStage finalModel(LemurModels finalModel) {
            this.finalModel = Optional.of(finalModel);
            return this;
        }

        @Override
        @JsonSetter(value = "final_model", nulls = Nulls.SKIP)
        public _FinalStage finalModel(Optional<LemurModels> finalModel) {
            this.finalModel = finalModel;
            return this;
        }

        /**
         * <p>Context to provide the model. This can be a string or a free-form JSON value.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @Override
        public _FinalStage context(LemurBaseParametersContext context) {
            this.context = Optional.of(context);
            return this;
        }

        @Override
        @JsonSetter(value = "context", nulls = Nulls.SKIP)
        public _FinalStage context(Optional<LemurBaseParametersContext> context) {
            this.context = context;
            return this;
        }

        /**
         * <p>A list of completed transcripts with text. Up to 100 files max, or 100 hours max. Whichever is lower.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @Override
        public _FinalStage addAllTranscriptIds(List<String> transcriptIds) {
            this.transcriptIds.addAll(transcriptIds);
            return this;
        }

        /**
         * <p>A list of completed transcripts with text. Up to 100 files max, or 100 hours max. Whichever is lower.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @Override
        public _FinalStage addTranscriptIds(String transcriptIds) {
            this.transcriptIds.add(transcriptIds);
            return this;
        }

        @Override
        @JsonSetter(value = "transcript_ids", nulls = Nulls.SKIP)
        public _FinalStage transcriptIds(List<String> transcriptIds) {
            this.transcriptIds.clear();
            this.transcriptIds.addAll(transcriptIds);
            return this;
        }

        @Override
        public LemurTaskParameters build() {
            return new LemurTaskParameters(transcriptIds, context, finalModel, maxOutputSize, temperature, prompt);
        }
    }
}
